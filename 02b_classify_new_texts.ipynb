{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify new texts\n",
    "\n",
    "And put the results in a naf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_AA.txt.xml  DB_CC.txt.xml  DB_EE.txt.xml  DB_GG.txt.xml  DB_II.txt.xml\r\n",
      "DB_BB.txt.xml  DB_DD.txt.xml  DB_FF.txt.xml  DB_HH.txt.xml  DB_JJ.txt.xml\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/jvdzwaan/data/tmp-naf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading body part mapping from /home/jvdzwaan/data/embem/dict/body_part_mapping.json\n",
      "ignored: rose-kaken (cheeks)\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_GG.txt.xml (1 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_GG.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_EE.txt.xml (2 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_EE.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_JJ.txt.xml (3 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_JJ.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_CC.txt.xml (4 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_CC.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_DD.txt.xml (5 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_DD.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_BB.txt.xml (6 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_BB.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_FF.txt.xml (7 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_FF.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_II.txt.xml (8 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_II.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_HH.txt.xml (9 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_HH.txt.xml\n",
      "\n",
      "/home/jvdzwaan/data/tmp-naf/DB_AA.txt.xml (10 of 10)\n",
      "writing /home/jvdzwaan/data/output/DB_AA.txt.xml\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run embem/kafnaftag/emotions_layer.py -c /home/jvdzwaan/data/embem/ml/classifier/classifier.pkl -d /home/jvdzwaan/data/embem/dict/hist2modern_bwnt.json -b /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/tmp-naf /home/jvdzwaan/data/output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB_AA.txt.xml  DB_CC.txt.xml  DB_EE.txt.xml  DB_GG.txt.xml  DB_II.txt.xml\r\n",
      "DB_BB.txt.xml  DB_DD.txt.xml  DB_FF.txt.xml  DB_HH.txt.xml  DB_JJ.txt.xml\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/jvdzwaan/data/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classifier and do predictions in notebook\n",
    "\n",
    "This is the 'old' way of making predictions. There is no script for putting the predictions in the naf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy required files for loading the classifier\n",
    "! cp embem/machinelearning/mlutils.py utils.py\n",
    "! cp embem/machinelearning/rakel.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load classifier\n",
    "from sklearn.externals import joblib\n",
    "from embem.machinelearning import mlutils as utils\n",
    "\n",
    "classifier = '/home/jvdzwaan/data/embem/ml/classifier/classifier.pkl'\n",
    "\n",
    "clf = joblib.load(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train file\n",
    "embem_data_dir = '/home/jvdzwaan/data/embem/'\n",
    "train_file = os.path.join(embem_data_dir, 'ml/all_spellingnormalized.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/jvdzwaan/data/tmp/normalized/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the path where output should be written\n",
    "out_dir = '/home/jvdzwaan/data/tmp/txt-predictions-normalized'\n",
    "os.makedirs(out_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 of 1) input.txt.xml.txt\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import os\n",
    "import codecs\n",
    "from utils import get_data, load_data\n",
    "\n",
    "text_files = [fi for fi in os.listdir(data_dir) if fi.endswith('.txt')]\n",
    "for i, text_file in enumerate(text_files):\n",
    "    in_file = os.path.join(data_dir, text_file)\n",
    "    print('({} of {}) {}'.format(i+1, len(text_files), text_file))\n",
    "\n",
    "    # load data\n",
    "    X_train, X_data, Y_train, Y_data, classes_ = get_data(train_file, in_file)\n",
    "\n",
    "    # classifiy\n",
    "    pred = clf.predict(X_data)\n",
    "\n",
    "    # save results\n",
    "    out_file = os.path.join(out_dir, text_file)\n",
    "\n",
    "    X_data_with_ids, Y_data = load_data(in_file)\n",
    "\n",
    "    with codecs.open(out_file, 'wb', 'utf8') as f:\n",
    "        for x, y in zip(X_data_with_ids, pred):\n",
    "            f.write(u'{}\\t{}\\n'.format(x.decode('utf8'),\n",
    "                                       '_'.join(classes_[y]) or 'None'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.txt.xml.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls /home/jvdzwaan/data/tmp/txt-predictions-normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.txt.p.1.s.1\tdeze zijn een tekst .\tNone\r\n",
      "input.txt.p.1.s.2\tEen mooi tets .\tNone\r\n"
     ]
    }
   ],
   "source": [
    "! cat /home/jvdzwaan/data/tmp/txt-predictions-normalized/input.txt.xml.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 of 1) input.txt.xml.txt\n"
     ]
    }
   ],
   "source": [
    "# make unnormalized version of predicted labels (needed before expanding body part labels)\n",
    "\n",
    "%run embem/machinelearningdata/merge_data_and_labels.py /home/jvdzwaan/data/tmp/txt-predictions-normalized /home/jvdzwaan/data/tmp/unnormalized/ /home/jvdzwaan/data/tmp/txt-predictions-unnormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.txt.p.1.s.1\tDit is een tekst .\tNone\r\n",
      "input.txt.p.1.s.2\tEen mooie test .\tNone\r\n"
     ]
    }
   ],
   "source": [
    "! cat /home/jvdzwaan/data/tmp/txt-predictions-unnormalized/input.txt.xml.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand body parts\n",
    "\n",
    "%run classify_body_parts.py /home/jvdzwaan/data/embem/dict/body_part_mapping.json /home/jvdzwaan/data/embem/txt/annotation-predicted-heem/ /home/jvdzwaan/data/embem/txt/annotation-predicted-heem-expanded_body_parts  /home/jvdzwaan/data/embem/dict/annotation_heem_expanded_body_parts.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
